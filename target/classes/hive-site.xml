<configuration>
    <property>
        <name>hive.server2.metrics.enabled</name>
        <value>true</value>
        <description>是否打开hiveserver2的监控项</description>
    </property>
    <property>
        <name>hive.exec.stagingdir</name>
        <value>.hive-staging</value>
        <description>设置临时目录</description>
    </property>
    <property>
        <name>hive.exec.scratchdir</name>
        <value>hdfs://jf-iceberg/tmp/hive</value>
        <description>用来存储不同阶段的map/reduce的执行计划的目录, 同时也存储中间输出结果</description>
    </property>
    <property>
        <name>hive.vectorized.groupby.checkinterval</name>
        <value>4096</value>
        <description>在对平均条目大小进行重新计算之前, 添加到GROUP BY聚合哈希中的条目数</description>
    </property>
    <property>
        <name>hive.vectorized.groupby.maxentries</name>
        <value>100000</value>
        <description>GROUP BY聚合哈希表中的最大条目数</description>
    </property>
    <property>
        <name>io.compression.codecs</name>
        <value>org.apache.hadoop.io.compress.GzipCodec,org.apache.hadoop.io.compress.DefaultCodec,org.apache.hadoop.io.compress.SnappyCodec,com.hadoop.compression.lzo.LzoCodec,com.hadoop.compression.lzo.LzopCodec</value>
        <description>声明可用的压缩算法的编/解码器</description>
    </property>
    <property>
        <name>javax.jdo.option.ConnectionDriverName</name>
        <value>com.mysql.jdbc.Driver</value>
        <description>JDBC元存储库的驱动程序类名称</description>
    </property>
    <property>
        <name>hive.insert.into.multilevel.dirs</name>
        <value>true</value>
        <description>要启用自动子目录生成</description>
    </property>
    <property>
        <name>datanucleus.connectionPool.maxPoolSize</name>
        <value>20</value>
        <description>指定连接池中的最大连接数</description>
    </property>
    <property>
        <name>hive.metastore.metrics.enabled</name>
        <value>true</value>
        <description>在Hive MetaStore Service上启用 Metrics</description>
    </property>
    <property>
        <name>hive.txn.manager</name>
        <value>org.apache.hadoop.hive.ql.lockmgr.DummyTxnManager</value>
        <description>DbTxnManager作为打开Hive事务的一部</description>
    </property>
    <property>
        <name>hive.txn.strict.locking.mode</name>
        <value>false</value>
        <description>在非严格模式下, 对于非 ACID 资源, INSERT将仅获取共享锁, 这允许两次并发写入同一分区, 但仍允许锁Management器在写入表时防止DROP TABLE等</description>
    </property>
    <property>
        <name>hive.user.install.directory</name>
        <value>/user/</value>
        <description>将Hive jar上传到此目录并使用它来运行查询</description>
    </property>
    <property>
        <name>hive.users.in.admin.role</name>
        <value>hive</value>
        <description>用逗号分隔的用户列表, 将在元存储启动时添加到ADMIN角色</description>
    </property>
    <property>
        <name>hive.vectorized.execution.enabled</name>
        <value>false</value>
        <description>是否启用查询执行的矢量化模式</description>
    </property>
    <property>
        <name>hive.vectorized.execution.mapjoin.minmax.enabled</name>
        <value>true</value>
        <description>此标志应设置为true, 以使矢量Map联接哈希表能够使用MapJoin对整数联接查询使用max/max过滤</description>
    </property>
    <property>
        <name>hive.vectorized.execution.mapjoin.native.fast.hashtable.enabled</name>
        <value>true</value>
        <description>此标志应设置为true, 以允许在使用MapJoin的查询中使用本机快速矢量Map联接哈希表</description>
    </property>
    <property>
        <name>hive.server2.thrift.port</name>
        <value>10000</value>
        <description>HiveServer2 Thrift 接口的端口号</description>
    </property>
    <property>
        <name>hive.server2.webui.cors.allowed.headers</name>
        <value>X-Requested-With,Content-Type,Accept,Origin,X-Requested-By,x-requested-by</value>
        <description>跨域设置</description>
    </property>
    <property>
        <name>hive.server2.webui.enable.cors</name>
        <value>true</value>
        <description>跨域设置</description>
    </property>
    <property>
        <name>hive.server2.webui.port</name>
        <value>10002</value>
        <description>HiveServer2 Web UI 将侦听的端口</description>
    </property>
    <property>
        <name>hive.service.metrics.codahale.reporter.classes</name>
        <value>org.apache.hadoop.hive.common.metrics.metrics2.JsonFileMetricsReporter,org.apache.hadoop.hive.common.metrics.metrics2.JmxMetricsReporter</value>
        <description>度量标准类org.apache.hadoop.hive.common.metrics.metrics2.CodahaleMetrics的报告程序实现类的逗号分隔列表</description>
    </property>
    <property>
        <name>hive.stats.fetch.column.stats</name>
        <value>true</value>
        <description>用统计信息Comments运算符树需要列统计信息</description>
    </property>
    <property>
        <name>hive.support.concurrency</name>
        <value>false</value>
        <description>Hive是否支持并发</description>
    </property>
    <property>
        <name>hive.server2.enable.doAs</name>
        <value>true</value>
        <description>将此属性设置为true将使 HiveServer2在用户对其进行调用时执行Hive操作</description>
    </property>
    <property>
        <name>hive.server2.idle.operation.timeout</name>
        <value>6h</value>
        <description>在此时间段内未访问操作时，操作将关闭</description>
    </property>
    <property>
        <name>hive.server2.idle.session.timeout</name>
        <value>1d</value>
        <description>在此时间段内未访问会话时，会话将关闭</description>
    </property>
    <property>
        <name>hive.server2.logging.operation.log.location</name>
        <value>/tmp/hive/operation_logs</value>
        <description>如果启用了日志记录功能，则存储操作日志的顶级目录</description>
    </property>
    <property>
        <name>hive.server2.max.start.attempts</name>
        <value>5</value>
        <description>HiveServer2 在退出之前尝试启动的次数</description>
    </property>
    <property>
        <name>hive.server2.support.dynamic.service.discovery</name>
        <value>true</value>
        <description>使hiveserver2服务可被动态发现</description>
    </property>
    <property>
        <name>hive.server2.thrift.http.port</name>
        <value>10003</value>
        <description>HTTP的监听端口</description>
    </property>
    <property>
        <name>hive.server2.thrift.max.worker.threads</name>
        <value>500</value>
        <description>Thrift 工作线程的最大数量</description>
    </property>
    <property>
        <name>hive.metastore.warehouse.dir</name>
        <value>hdfs://jf-iceberg/hive/warehouse</value>
        <description>仓库的默认数据库的位置</description>
    </property>
    <property>
        <name>hive.metastore.warehouse.external.dir</name>
        <value>/warehouse/tablespace/external/hive</value>
        <description>Hive外部表的存储位置</description>
    </property>
    <property>
        <name>hive.optimize.bucketmapjoin</name>
        <value>true</value>
        <description>如果表中的数据按照ON语句中的键进行分桶, 并且其中一张表的分桶的个数是另一张表的分桶个数若干倍, 那么hive可以在map阶段按照分桶数据进行连接</description>
    </property>
    <property>
        <name>hive.optimize.dynamic.partition.hashjoin</name>
        <value>true</value>
        <description>hashjoin</description>
    </property>
    <property>
        <name>hive.optimize.index.filter</name>
        <value>true</value>
        <description>是否启用索引自动使用</description>
    </property>
    <property>
        <name>hive.optimize.metadataonly</name>
        <value>true</value>
        <description>metadataonly</description>
    </property>
    <property>
        <name>hive.server2.authentication</name>
        <value>KERBEROS</value>
        <description>hiveserver2认证方式</description>
    </property>
    <property>
        <name>hive.merge.smallfiles.avgsize</name>
        <value>67108864</value>
        <description>当输出文件的平均大小小于该值时。启动一个独立的map-reduce任务进行文件merge</description>
    </property>
    <property>
        <name>hive.metastore.client.connect.retry.delay</name>
        <value>3</value>
        <description>MetaStore客户端重连/重试等待的时间</description>
    </property>
    <property>
        <name>hive.metastore.client.socket.timeout</name>
        <value>1200</value>
        <description>MetaStore客户端socket超时时间, 传递给底层Socket, 超时之后底层Socket会自动断开</description>
    </property>
    <property>
        <name>hive.metastore.connect.retries</name>
        <value>10</value>
        <description>客户端建立与metastore连接时的重试次数</description>
    </property>
    <property>
        <name>hive.metastore.db.type</name>
        <value>MYSQL</value>
        <description>metastore类型</description>
    </property>
    <property>
        <name>hive.metastore.failure.retries</name>
        <value>24</value>
        <description>客户端访问metastore的失败重试次数</description>
    </property>
    <property>
        <name>hive.metastore.sasl.enabled</name>
        <value>true</value>
        <description>如果为true, 则将使用SASL保护metastore旧版接口</description>
    </property>
    <property>
        <name>hive.metastore.server.max.threads</name>
        <value>100000</value>
        <description>Thrift服务器池中的最大工作线程数</description>
    </property>
    <property>
        <name>hive.hook.proto.base-directory</name>
        <value>/apps/hive/sys.db/query_data/</value>
        <description>proto</description>
    </property>
    <property>
        <name>hive.limit.optimize.enable</name>
        <value>true</value>
        <description>开启对数据源进行采样的功能</description>
    </property>
    <property>
        <name>hive.limit.pushdown.memory.usage</name>
        <value>0.1f</value>
        <description>在order by limit查询中分配给存储Top K的内存为10%</description>
    </property>
    <property>
        <name>hive.lock.manager</name>
        <value>org.apache.hadoop.hive.ql.lockmgr.zookeeper.ZooKeeperHiveLockManager</value>
        <description>设置为true时要使用的锁Management器</description>
    </property>
    <property>
        <name>hive.mapjoin.bucket.cache.size</name>
        <value>10000</value>
        <description>MapJoin桶的缓存大小, 以字节为单位</description>
    </property>
    <property>
        <name>hive.mapred.reduce.tasks.speculative.execution</name>
        <value>false</value>
        <description>是否应该对减速器进行投机执行</description>
    </property>
    <property>
        <name>hive.merge.mapredfiles</name>
        <value>true</value>
        <description>合并reduce端输出的结果</description>
    </property>
    <property>
        <name>hive.exec.compress.output</name>
        <value>true</value>
        <description>控制hive的查询结果输出是否进行压缩</description>
    </property>
    <property>
        <name>hive.exec.dynamic.partition</name>
        <value>true</value>
        <description>是否开启动态分区</description>
    </property>
    <property>
        <name>hive.exec.max.dynamic.partitions</name>
        <value>5000</value>
        <description>在所有执行MR的节点上, 最大一共可以创建多少个动态分区</description>
    </property>
    <property>
        <name>hive.exec.max.dynamic.partitions.pernode</name>
        <value>2000</value>
        <description>在每个执行MR的节点上, 最大可以创建多少个动态分区</description>
    </property>
    <property>
        <name>hive.exec.post.hooks</name>
        <value>org.apache.hadoop.hive.ql.hooks.HiveProtoLoggingHook</value>
        <description>将为每个语句调用的逗号分隔的执行后钩子列表</description>
    </property>
    <property>
        <name>hive.exec.pre.hooks</name>
        <value>org.apache.hadoop.hive.ql.hooks.HiveProtoLoggingHook</value>
        <description>将为每个语句调用的逗号分隔的预执行钩子列表</description>
    </property>
    <property>
        <name>hive.execution.engine</name>
        <value>mr</value>
        <description>hive执行引擎</description>
    </property>
    <property>
        <name>hive.cbo.enable</name>
        <value>true</value>
        <description>调整Join顺序, 让多次Join产生的中间数据尽可能小, 选择不同的Join策略</description>
    </property>
    <property>
        <name>hive.compactor.initiator.on</name>
        <value>false</value>
        <description>是否在这个 MetaStore 实例上运行启动器和清理器线程</description>
    </property>
    <property>
        <name>hive.compactor.worker.threads</name>
        <value>5</value>
        <description>工作线程的数量, 将此设置为正数以启用 Hive 事务</description>
    </property>
    <property>
        <name>hive.compute.query.using.stats</name>
        <value>true</value>
        <description>读取表级统计信息里面的数据</description>
    </property>
    <property>
        <name>hive.default.fileformat</name>
        <value>ORC</value>
        <description>hive的默认文件的表存储格式</description>
    </property>
    <property>
        <name>hive.default.fileformat.managed</name>
        <value>ORC</value>
        <description>hive的默认文件的外部表存储格式</description>
    </property>
    <property>
        <name>hive.driver.parallel.compilation</name>
        <value>true</value>
        <description>是否开启一次性编译多个sql的功能</description>
    </property>
    <property>
        <name>datanucleus.fixedDatastore</name>
        <value>true</value>
        <description>默认情况下,设置为true, 这会阻止意外更改元存储数据库的结构</description>
    </property>
    <property>
        <name>hive.auto.convert.join</name>
        <value>true</value>
        <description>是否根据输入小表的大小, 自动将Reduce端的Common Join转化为Map Join, 从而加快大表关联小表的Join速度</description>
    </property>
    <property>
        <name>hive.auto.convert.join.noconditionaltask</name>
        <value>true</value>
        <description>开启多路join加载到map中的开关</description>
    </property>
    <property>
        <name>hive.auto.convert.join.noconditionaltask.size</name>
        <value>20971520</value>
        <description>当n-1个表的总和小于等于该值时启动n-way mapjoin</description>
    </property>
    <property>
        <name>hive.auto.convert.sortmerge.join</name>
        <value>true</value>
        <description>是否当连接的两个表满足smb条件时(有序的分桶)自动采用sbmJoin</description>
    </property>
    <property>
        <name>hive.auto.convert.sortmerge.join.to.mapjoin</name>
        <value>true</value>
        <description>join的表中有相对小的表时, 是否将smb转为mapjoin</description>
    </property>
    <property>
        <name>hive.server2.zookeeper.namespace</name>
        <value>hiveserver2</value>
        <description>Hive Server2使用ZooKeeper的命名空间</description>
    </property>
    <property>
        <name>hive.security.authorization.sqlstd.confwhitelist</name>
        <value>mapred.*|hive.*|mapreduce.*|spark.*|bdms.*|dpi.*</value>
        <description>SQL标准授权的白名单，允许哪些操作</description>
    </property>
    <property>
        <name>hive.security.authorization.sqlstd.confwhitelist.append</name>
        <value>mapred.*|hive.*|mapreduce.*|spark.*|bdms.*|dpi.*</value>
        <description>追加到SQL标准授权的白名单，以允许更多操作</description>
    </property>
    <property>
        <name>hive.cluster.delegation.token.store.class</name>
        <value>org.apache.hadoop.hive.metastore.security.DBTokenStore</value>
        <description>Hive集群的代理令牌存储类</description>
    </property>
    <property>
        <name>hive.zookeeper.client.port</name>
        <value>2181</value>
        <description>ZooKeeper客户端连接的端口</description>
    </property>
    <property>
        <name>hive.aux.jars.path</name>
        <value>file:///usr/local/hive/auxlib/hudi-hive-sync-bundle-0.12.2.jar,file:///usr/local/hive/auxlib/hudi-hadoop-mr-bundle-0.12.2.jar</value>
        <description>Hive附加JAR文件的路径，这些JAR文件可以用于扩展Hive功能</description>
    </property>
    <property>
        <name>hive.exec.input.listing.max.threads</name>
        <value>64</value>
        <description>监听输入文件的最大线程数。当需要读取大量分区时，增加这个值可以提高性能。请根据服务器配置进行调整</description>
    </property>
    <property>
        <name>hive.load.dynamic.partitions.thread</name>
        <value>30</value>
        <description>动态分区加载线程数</description>
    </property>
    <property>
        <name>metastore.thread.pool.size</name>
        <value>30</value>
        <description>metastore的线程池</description>
    </property>
    <property>
        <name>hive.orc.compute.splits.num.threads</name>
        <value>20</value>
        <description>orc计算拆分线程数</description>
    </property>
    <property>
        <name>hive.stats.gather.num.threads</name>
        <value>20</value>
        <description>静态统计线程数</description>
    </property>
    <property>
        <name>engine.hive.enabled</name>
        <value>true</value>
        <description>启用Hive查询引擎</description>
    </property>
    <property>
        <name>iceberg.engine.hive.enabled</name>
        <value>true</value>
        <description>启用Hive支持Iceberg数据格式的查询引擎</description>
    </property>
    <property>
        <name>javax.jdo.option.ConnectionURL</name>
        <value>jdbc:mysql://192.168.9.11:3306/hive?createDatabaseIfNotExist=true</value>
        <description>JDBC metastore的JDBC连接字符串</description>
    </property>
    <property>
        <name>javax.jdo.option.ConnectionUserName</name>
        <value>emrhive</value>
        <description>用于MetaStore数据库的用户名</description>
    </property>
    <property>
        <name>javax.jdo.option.ConnectionPassword</name>
        <value>}u9MU!u]QGD~YBvFo1ok</value>
        <description>用于MetaStore数据库的密码</description>
    </property>
    <property>
        <name>hive.metastore.kerberos.keytab.file</name>
        <value>/etc/security/keytabs/hive.keytab</value>
        <description>Kerberos Keytab文件的路径</description>
    </property>
    <property>
        <name>hive.metastore.kerberos.principal</name>
        <value>hive/_HOST@HADOOP.CHINATELECOM.CN</value>
        <description>MetaStore服务器的服务主体</description>
    </property>
    <property>
        <name>hive.metastore.uris</name>
        <value>thrift://jfdkhadoop007:9083,thrift://jfdkhadoop006:9083</value>
    </property>
    <property>
        <name>hive.server2.authentication.kerberos.keytab</name>
        <value>/etc/security/keytabs/hive.keytab</value>
        <description>服务器主体的Kerberos密钥文件</description>
    </property>
    <property>
        <name>hive.server2.authentication.kerberos.principal</name>
        <value>hive/_HOST@HADOOP.CHINATELECOM.CN</value>
        <description>Kerberos服务器主体</description>
    </property>
    <property>
        <name>hive.zookeeper.quorum</name>
        <value>jfdkhadoop018:2181,jfdkhadoop019:2181,jfdkhadoop020:2181</value>
        <description>ZooKeeper服务器列表</description>
    </property>
    <property>
        <name>hive.server2.thrift.bind.host</name>
        <value>192.168.8.194</value>
        <description>配置thrift服务绑定的ip</description>
    </property>
    <property>
        <name>hive.security.authorization.manager</name>
        <value>org.apache.ranger.authorization.hive.authorizer.RangerHiveAuthorizerFactory</value>
    </property>
    <property>
        <name>hive.security.authenticator.manager</name>
        <value>org.apache.hadoop.hive.ql.security.SessionStateUserAuthenticator</value>
    </property>
    <property>
        <name>hive.security.authorization.enabled</name>
        <value>true</value>
    </property>
</configuration>
